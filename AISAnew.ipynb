{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVxVqe5DqOcc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "MslGRuGjtxP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jessicali9530/lfw-dataset"
      ],
      "metadata": {
        "id": "nuv1AG0qtzSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q lfw-dataset.zip\n",
        "print(\"✅ LFW Dataset is ready!\")"
      ],
      "metadata": {
        "id": "g5FGYCl5t229"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Creating a larger, balanced data subset ---\")\n",
        "# --- Configuration ---\n",
        "SOURCE_DIR = 'lfw-deepfunneled/lfw-deepfunneled/'\n",
        "SUBSET_DIR = 'lfw-subset-large/' # New directory for the larger subset\n",
        "NUM_CLASSES = 200 # Increased from 100\n",
        "MIN_IMAGES = 15\n",
        "MAX_IMAGES = 80\n",
        "\n",
        "# --- Create a Clean Subset Directory ---\n",
        "if os.path.exists(SUBSET_DIR):\n",
        "    shutil.rmtree(SUBSET_DIR)\n",
        "os.makedirs(SUBSET_DIR)\n",
        "\n",
        "# --- Find and Select People ---\n",
        "all_identities = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
        "identity_counts = {identity: len(os.listdir(os.path.join(SOURCE_DIR, identity))) for identity in all_identities}\n",
        "filtered_identities = {identity: count for identity, count in identity_counts.items() if MIN_IMAGES <= count <= MAX_IMAGES}\n",
        "selected_identities = list(filtered_identities.keys())[:NUM_CLASSES]\n",
        "\n",
        "print(f\"Creating subset with {len(selected_identities)} identities...\")\n",
        "for identity in tqdm(selected_identities):\n",
        "    shutil.copytree(os.path.join(SOURCE_DIR, identity), os.path.join(SUBSET_DIR, identity))\n",
        "print(f\"\\n✅ Large subset created at '{SUBSET_DIR}'\")"
      ],
      "metadata": {
        "id": "9EHS9AGEt5lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n--- Loading data and building the final model ---\")\n",
        "# --- Configuration ---\n",
        "IMG_SIZE = (260, 260)\n",
        "BATCH_SIZE = 32\n",
        "# Make sure SUBSET_DIR is defined with the path to your dataset\n",
        "# SUBSET_DIR = \"path/to/your/lfw_subset\"\n",
        "\n",
        "# --- Data Loading ---\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    SUBSET_DIR, validation_split=0.2, subset=\"training\", seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
        ")\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    SUBSET_DIR, validation_split=0.2, subset=\"validation\", seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
        ")\n",
        "class_names = train_dataset.class_names\n",
        "print(f\"Loaded {len(class_names)} classes.\")\n",
        "\n",
        "# --- Data Augmentation Layer ---\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# --- Build the Model using EfficientNetB2 ---\n",
        "base_model = tf.keras.applications.EfficientNetB2(\n",
        "    input_shape=(260, 260, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False # Keep the base frozen for initial training\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(260, 260, 3)),\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "# --- Compile and Initial Training ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- ADDED: Callbacks for smarter training ---\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"face_model_best.keras\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5, # Stop if validation loss doesn't improve for 5 epochs\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Initial Training (Phase 1) ---\")\n",
        "# --- CHANGED: Increased epochs and added callbacks ---\n",
        "initial_epochs = 50\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=initial_epochs,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback] # Use callbacks\n",
        ")\n",
        "\n",
        "# ==========================================================\n",
        "# --- ADDED: Fine-Tuning Stage (Phase 2) ---\n",
        "# ==========================================================\n",
        "print(\"\\n--- Starting Fine-Tuning (Phase 2) ---\")\n",
        "base_model.trainable = True # Unfreeze the base model\n",
        "\n",
        "# Re-compile the model with a very low learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # 0.00001\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Continue training for a few more epochs\n",
        "fine_tune_epochs = 20\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history.epoch[-1], # Start from where we left off\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback] # Reuse the same callbacks\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training complete. Best model saved to 'face_model_best.keras' ---\")"
      ],
      "metadata": {
        "id": "9GUZv_V4t79Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Starting Final Fine-Tuning ---\")\n",
        "base_model.trainable = True\n",
        "\n",
        "# Unfreeze the top 1/3 of the model (approx.)\n",
        "fine_tune_at = len(base_model.layers) // 3\n",
        "for layer in base_model.layers[:-fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# --- Learning Rate Scheduler Callback ---\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2, # Reduce LR by a factor of 5\n",
        "    patience=2, # after 2 epochs of no improvement\n",
        "    verbose=1,\n",
        "    min_lr=1e-7 # Don't let the LR get too small\n",
        ")\n",
        "\n",
        "# Re-compile with a low initial learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Continue training with the scheduler\n",
        "fine_tune_epochs = 30\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[lr_scheduler] # Add the callback here\n",
        ")\n",
        "print(\"\\n✅ Final fine-tuning complete!\")"
      ],
      "metadata": {
        "id": "Ru_gk5VLuBCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n--- Running Final Predictions on Validation Images ---\")\n",
        "plt.figure(figsize=(10, 12))\n",
        "for images, labels in validation_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        img_array = tf.expand_dims(images[i], 0)\n",
        "        # Use the final_model for predictions\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class_index = np.argmax(predictions[0])\n",
        "        confidence = 100 * np.max(predictions[0])\n",
        "\n",
        "        actual_name = class_names[labels[i]]\n",
        "        predicted_name = class_names[predicted_class_index]\n",
        "\n",
        "        plt.title(f\"Actual: {actual_name}\\nPredicted: {predicted_name}\\nConf: {confidence:.2f}%\")\n",
        "        plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "InaeKTe-uHMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After the model.fit() call for your LFW model is complete\n",
        "print(\"--- Saving the trained face recognition model ---\")\n",
        "model.save('face_recognition_lfw_model.keras')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "f7edJ_CIuJUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mstjebashazida/affectnet"
      ],
      "metadata": {
        "id": "-N4nWYu8uMmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q affectnet.zip -d affectnet_data"
      ],
      "metadata": {
        "id": "4Sc6C1Wyuh9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls affectnet_data"
      ],
      "metadata": {
        "id": "O8QBStNZunFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "IMG_SIZE = (260, 260)\n",
        "BATCH_SIZE = 32\n",
        "DATA_DIR = 'affectnet_data/'"
      ],
      "metadata": {
        "id": "6qiwyiK2upWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = 'affectnet_data/'\n",
        "IMAGE_BASE_DIR = os.path.join(DATA_DIR, 'archive (3)', 'Train/')\n",
        "csv_path = os.path.join(DATA_DIR, 'archive (3)', 'labels.csv')\n",
        "IMG_SIZE = (260, 260)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "_gVWGVkPurgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Loading and processing DataFrame ---\")\n",
        "df = pd.read_csv(csv_path)\n",
        "df['full_path'] = IMAGE_BASE_DIR + df['pth']\n",
        "class_names = sorted(df['label'].unique())\n",
        "label_to_id = {label: i for i, label in enumerate(class_names)}\n",
        "df['numeric_label'] = df['label'].map(label_to_id)\n",
        "print(\"DataFrame successfully processed.\")"
      ],
      "metadata": {
        "id": "UWbTG9IXutf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- DataFrame Head ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- DataFrame Info (Check Dtypes) ---\")\n",
        "df.info()\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "QgtDl_HfuvVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating tf.data.Dataset ---\")\n",
        "image_paths = df['full_path'].values\n",
        "emotion_labels = df['numeric_label'].values\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, emotion_labels))"
      ],
      "metadata": {
        "id": "Piid9s4LuxGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = sorted(df['label'].unique())\n",
        "print(f\"Found {len(class_names)} classes: {class_names}\")\n",
        "label_to_id = {label: i for i, label in enumerate(class_names)}\n",
        "df['numeric_label'] = df['label'].map(label_to_id)"
      ],
      "metadata": {
        "id": "HwYmJjAOuzEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = df['full_path'].values\n",
        "emotion_labels = df['numeric_label'].values\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, emotion_labels))"
      ],
      "metadata": {
        "id": "Gh8heC8zu0ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_data(path, label):\n",
        "    is_valid = tf.py_function(\n",
        "        lambda p: tf.io.gfile.exists(p.numpy().decode('utf-8')),\n",
        "        [path],\n",
        "        tf.bool\n",
        "    )\n",
        "    is_valid.set_shape([])\n",
        "    return is_valid"
      ],
      "metadata": {
        "id": "yAjmxtYeu4T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "wxLQVGTBu7Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.filter(is_valid_data)\n",
        "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.repeat() # Added to prevent training from stopping after one epoch\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "uEx_gdFzu81l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n✅ tf.data pipeline created successfully.\")\n",
        "print(\"Example batch from the dataset:\")\n",
        "for images, labels in dataset.take(1):\n",
        "    print(f\"Images shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "id": "8xNaiD_-u-t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "zdcUt59UvA6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Loading the base face recognition model ---\")\n",
        "saved_model = tf.keras.models.load_model('face_recognition_lfw_model.keras')"
      ],
      "metadata": {
        "id": "1Bt_ynDKvCux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Extracting the pre-trained base layer ---\")\n",
        "try:\n",
        "    # Use the name we confirmed from the model summary\n",
        "    base_model = saved_model.get_layer('efficientnetb2')\n",
        "    base_model.trainable = False # Freeze the weights\n",
        "    print(\"Base layer extracted and frozen successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please ensure 'efficientnetb2' is the correct layer name from saved_model.summary().\")"
      ],
      "metadata": {
        "id": "Utlo2Nl2vTWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EMOTION_CLASSES = len(class_names)\n",
        "\n",
        "inputs = Input(shape=(260, 260, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "outputs = Dense(NUM_EMOTION_CLASSES, activation='softmax', name='emotion_output')(x)\n",
        "emotion_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(\"\\n--- New Emotion Model Summary ---\")\n",
        "emotion_model.summary()"
      ],
      "metadata": {
        "id": "AyN3ZprnvU5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Starting Training on AffectNet ---\")\n",
        "emotion_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = emotion_model.fit(\n",
        "    dataset,\n",
        "    epochs=20,\n",
        "    # steps_per_epoch is needed because the dataset repeats indefinitely\n",
        "    steps_per_epoch=len(df) // BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "OcvKV0kxvWp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Saving the trained emotion model ---\")\n",
        "emotion_model.save('emotion_recognition_model.keras')\n",
        "print(\"✅ Emotion model saved successfully!\")"
      ],
      "metadata": {
        "id": "lxzb6ot6vYnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load and re-save the Emotion Model\n",
        "try:\n",
        "    emotion_model = tf.keras.models.load_model('emotion_recognition_model.keras', compile=False)\n",
        "    emotion_model.save('fixed_emotion_recognition_model.keras')\n",
        "    print(\"Emotion model re-saved successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error re-saving emotion model: {e}\")"
      ],
      "metadata": {
        "id": "GnEqAu_4vauA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get one batch of images and labels from the dataset\n",
        "image_batch, label_batch = next(iter(dataset))\n",
        "\n",
        "# Make predictions on the batch\n",
        "predictions = emotion_model.predict(image_batch)\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# The 'class_names' variable should still be available from your data prep script\n",
        "# It's an array like ['anger', 'contempt', ...]\n",
        "predicted_labels = [class_names[i] for i in predicted_indices]\n",
        "actual_labels = [class_names[i] for i in label_batch.numpy()]\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(min(9, BATCH_SIZE)):  # Display up to 9 images\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(f\"Actual: {actual_labels[i]}\\nPredicted: {predicted_labels[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_2dqTHAvdV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# --- 1. Load All Your Trained Models ---\n",
        "try:\n",
        "    # NOTE: The emotion model might need the softmax if it was trained without one.\n",
        "    # We will assume it does for this example.\n",
        "    emotion_model = tf.keras.models.load_model('emotion_recognition_model.keras')\n",
        "    emotion_class_names = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "    # Load the face model you trained\n",
        "    face_id_model = tf.keras.models.load_model('face_recognition_lfw_model.keras')\n",
        "\n",
        "    # Get class names in the correct order\n",
        "    print(\"Getting the official class names for the Face ID model...\")\n",
        "    temp_face_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        'lfw-subset-large/',\n",
        "        image_size=(260, 260),\n",
        "        batch_size=1\n",
        "    )\n",
        "    face_id_class_names = temp_face_dataset.class_names\n",
        "    print(f\"Found {len(face_id_class_names)} identities.\")\n",
        "\n",
        "    print(\"\\nAll models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading a model or getting class names: {e}\")\n",
        "\n",
        "# --- 2. Prepare the Image for Both Models ---\n",
        "image_path = '/content/beckham.jpeg'\n",
        "img = tf.keras.utils.load_img(image_path, target_size=(260, 260))\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array_batch = np.expand_dims(img_array, 0)\n",
        "\n",
        "# --- 3. Run Predictions with Correct Labels ---\n",
        "print(\"\\n--- Running Full Analysis ---\")\n",
        "\n",
        "# Emotion Prediction\n",
        "emotion_predictions = emotion_model.predict(img_array_batch)\n",
        "emotion_score = tf.nn.softmax(emotion_predictions[0]) # Keep this if emotion model outputs logits\n",
        "predicted_emotion = emotion_class_names[np.argmax(emotion_score)]\n",
        "emotion_confidence = 100 * np.max(emotion_score)\n",
        "print(f\"Predicted Emotion: '{predicted_emotion}' ({emotion_confidence:.2f}%)\")\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "# Face Identification Prediction\n",
        "face_id_predictions = face_id_model.predict(img_array_batch)\n",
        "# DO NOT apply softmax again. The model's output is already a probability distribution.\n",
        "face_id_score = face_id_predictions[0]\n",
        "predicted_person = face_id_class_names[np.argmax(face_id_score)]\n",
        "face_id_confidence = 100 * np.max(face_id_score) # This will now show the true confidence\n",
        "# --- END OF FIX ---\n",
        "\n",
        "print(f\"Closest Identity Match in LFW: '{predicted_person}' ({face_id_confidence:.2f}%)\")\n",
        "\n",
        "# --- 4. Display the Image ---\n",
        "display(Image.open(image_path))"
      ],
      "metadata": {
        "id": "dxukVqbqvjS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}